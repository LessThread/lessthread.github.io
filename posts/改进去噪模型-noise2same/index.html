<!doctype html><html lang=zh-cn dir=ltr class=scroll-smooth data-default-appearance=dark data-auto-appearance=true><head><meta charset=utf-8><meta http-equiv=content-language content="zh"><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><title>改进去噪模型-Noise2Same &#183; Lessthread's Blog</title>
<meta name=title content="改进去噪模型-Noise2Same &#183; Lessthread's Blog"><meta name=description content="对Noise2Same模型的优化与对比"><link rel=canonical href=https://blog.lessthread.top/posts/%E6%94%B9%E8%BF%9B%E5%8E%BB%E5%99%AA%E6%A8%A1%E5%9E%8B-noise2same/><link type=text/css rel=stylesheet href=/css/main.bundle.min.1c9cd0d1ebaf117272b5c4f6bd49878475cb210d5e0da4f061632d779f5bb46851881c187e6e634dba5071c4e3d80e7d5cec1dd80443b2fa68acd358f9eda881.css integrity="sha512-HJzQ0euvEXJytcT2vUmHhHXLIQ1eDaTwYWMtd59btGhRiBwYfm5jTbpQccTj2A59XOwd2ARDsvporNNY+e2ogQ=="><script type=text/javascript src=/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj+e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script><script defer type=text/javascript id=script-bundle src=/js/main.bundle.min.c178288131a2f1ad46910438db47ac5f7e1c48cf949e49f6dc3310c8ec9660e23fe505805eba4e2e73711335808500360d773a2b64322feb35df52856edca286.js integrity="sha512-wXgogTGi8a1GkQQ420esX34cSM+Unkn23DMQyOyWYOI/5QWAXrpOLnNxEzWAhQA2DXc6K2QyL+s131KFbtyihg==" data-copy data-copied></script><script src=/lib/zoom/zoom.min.37d2094687372da3f7343a221a470f6b8806f7891aa46a5a03966af7f0ebd38b9fe536cb154e6ad28f006d184b294525a7c4054b6bbb4be62d8b453b42db99bd.js integrity="sha512-N9IJRoc3LaP3NDoiGkcPa4gG94kapGpaA5Zq9/Dr04uf5TbLFU5q0o8AbRhLKUUlp8QFS2u7S+Yti0U7QtuZvQ=="></script><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=manifest href=/site.webmanifest><meta property="og:url" content="https://blog.lessthread.top/posts/%E6%94%B9%E8%BF%9B%E5%8E%BB%E5%99%AA%E6%A8%A1%E5%9E%8B-noise2same/"><meta property="og:site_name" content="Lessthread's Blog"><meta property="og:title" content="改进去噪模型-Noise2Same"><meta property="og:description" content="对Noise2Same模型的优化与对比"><meta property="og:locale" content="zh"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2024-01-17T13:58:22+00:00"><meta property="article:modified_time" content="2024-01-17T13:58:22+00:00"><meta name=twitter:card content="summary"><meta name=twitter:title content="改进去噪模型-Noise2Same"><meta name=twitter:description content="对Noise2Same模型的优化与对比"><script type=application/ld+json>[{"@context":"https://schema.org","@type":"Article","articleSection":"","name":"改进去噪模型-Noise2Same","headline":"改进去噪模型-Noise2Same","description":"对Noise2Same模型的优化与对比","inLanguage":"zh","url":"https:\/\/blog.lessthread.top\/posts\/%E6%94%B9%E8%BF%9B%E5%8E%BB%E5%99%AA%E6%A8%A1%E5%9E%8B-noise2same\/","author":{"@type":"Person","name":"Lessthread"},"copyrightYear":"2024","dateCreated":"2024-01-17T13:58:22\u002b00:00","datePublished":"2024-01-17T13:58:22\u002b00:00","dateModified":"2024-01-17T13:58:22\u002b00:00","mainEntityOfPage":"true","wordCount":"419"}]</script><meta name=author content="Lessthread"><link href=mailto:mail@lessthread.top rel=me><link href=https://github.com/lessthread rel=me><script src=/lib/jquery/jquery.slim.min.b0dca576e87d7eaa5850ae4e61759c065786cdb6489d68fcc82240539eebd5da522bdb4fda085ffd245808c8fe2acb2516408eb774ef26b5f6015fc6737c0ea8.js integrity="sha512-sNylduh9fqpYUK5OYXWcBleGzbZInWj8yCJAU57r1dpSK9tP2ghf/SRYCMj+KsslFkCOt3TvJrX2AV/Gc3wOqA=="></script><meta name=theme-color></head><body class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600"><div id=the-top class="absolute flex self-center"><a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600" href=#main-content><span class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>跳过正文</a></div><div style=padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start gap-x-3"><div class="flex flex-1 items-center justify-between"><nav class="flex space-x-3"><a href=/ class="text-base font-medium text-gray-500 hover:text-gray-900">Lessthread&rsquo;s Blog</a></nav><nav class="hidden md:flex items-center gap-x-5 md:ml-12 h-12"><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-base font-medium" title>博客</p></a><button id=search-button aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></button><div class="flex items-center"><button id=appearance-switcher aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></nav><div class="flex md:hidden items-center gap-x-5 md:ml-12 h-12"><span></span>
<button id=search-button-mobile aria-label=Search class="text-base hover:text-primary-600 dark:hover:text-primary-400" title>
<span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>
</span></button>
<button id=appearance-switcher-mobile aria-label="Dark mode switcher" type=button class="text-base hover:text-primary-600 dark:hover:text-primary-400 ltr:mr-1 rtl:ml-1"><div class="flex items-center justify-center dark:hidden"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M32 256C32 132.2 132.3 32 255.8 32c11.36.0 29.7 1.668 40.9 3.746 9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3 9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480 132.1 480 32 379.6 32 256z"/></svg></span></div><div class="items-center justify-center hidden dark:flex"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M256 159.1c-53.02.0-95.1 42.98-95.1 95.1s41.2 96.9 95.1 96.9 95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347l-63.2-91.9 63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89 164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6 12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256 2.74 347.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7 19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109 109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69.0-127.1-57.31-127.1-127.1.0-70.69 57.31-127.1 127.1-127.1S383.1 186.2 383.1 256c0 70.7-56.4 127.1-127.1 127.1z"/></svg></span></div></button></div></div><div class="-my-2 md:hidden"><label id=menu-button class=block><div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 448 512"><path fill="currentcolor" d="M0 96C0 78.33 14.33 64 32 64H416c17.7.0 32 14.33 32 32 0 17.7-14.3 32-32 32H32C14.33 128 0 113.7.0 96zM0 256c0-17.7 14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32H32c-17.67.0-32-14.3-32-32zM416 448H32c-17.67.0-32-14.3-32-32s14.33-32 32-32H416c17.7.0 32 14.3 32 32s-14.3 32-32 32z"/></svg></span></div><div id=menu-wrapper style=padding-top:5px class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50"><ul class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl"><li id=menu-close-button><span class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400"><span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></span></li><li class=mt-1><a href=/posts/ class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400"><p class="text-bg font-bg" title>博客</p></a></li></ul></div></label></div></div><div class="relative flex flex-col grow"><main id=main-content class=grow><article><header id=single_header class="mt-5 max-w-prose"><h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">改进去噪模型-Noise2Same</h1><div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden"><div class="flex flex-row flex-wrap items-center"><time datetime=2024-01-17T13:58:22+00:00>2024 January 17</time><span class="px-2 text-primary-500">&#183;</span><span>419 字</span><span class="px-2 text-primary-500">&#183;</span><span title=预计阅读>2 分钟</span></div></div><div class="flex author"><img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width=96 height=96 alt=Lessthread src=/img/pro_hu1627740463050593498.jpg><div class=place-self-center><div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">作者</div><div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">Lessthread</div><div class="text-2xl sm:text-lg"><div class="flex flex-wrap text-neutral-400 dark:text-neutral-500"><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=mailto:mail@lessthread.top target=_blank aria-label=Email rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 512 512"><path fill="currentcolor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1-27.64 140.9 68.65 266.2 199.1 285.1 19.01 2.888 36.17-12.26 36.17-31.49l1e-4-.6631c0-15.74-11.44-28.88-26.84-31.24-84.35-12.98-149.2-86.13-149.2-174.2.0-102.9 88.61-185.5 193.4-175.4 91.54 8.869 158.6 91.25 158.6 183.2v16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98.0036c-7.299.0-13.2 4.992-15.12 11.68-24.85-12.15-54.24-16.38-86.06-5.106-38.75 13.73-68.12 48.91-73.72 89.64-9.483 69.01 43.81 128 110.9 128 26.44.0 50.43-9.544 69.59-24.88 24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3c0-149.2-133.9-265.632-287.3-235.57zM239.1 304.3c-26.47.0-48-21.56-48-48.05s21.53-48.05 48-48.05 48 21.56 48 48.05-20.6 48.05-48 48.05z"/></svg>
</span></span></a><a class="px-1 hover:text-primary-700 dark:hover:text-primary-400" href=https://github.com/lessthread target=_blank aria-label=Github rel="me noopener noreferrer"><span class="inline-block align-text-bottom"><span class="relative block icon"><svg viewBox="0 0 496 512"><path fill="currentcolor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6.0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6.0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3.0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1.0-6.2-.3-40.4-.3-61.4.0.0-70 15-84.7-29.8.0.0-11.4-29.1-27.8-36.6.0.0-22.9-15.7 1.6-15.4.0.0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5.0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9.0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4.0 33.7-.3 75.4-.3 83.6.0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6.0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9.0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg></span></span></a></div></div></div></div><div class=mb-5></div></header><section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row"><div class="min-w-0 min-h-0 max-w-fit"><div class="article-content max-w-prose mb-20"><h1 class="relative group">前言<div id=%E5%89%8D%E8%A8%80 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%89%8D%E8%A8%80 aria-label=锚点>#</a></span></h1><p>基于N2S模型进行了修改</p><p><a href=https://github.com/LessThread/Noise2SamePro target=_blank>源码地址</a><br><a id=readme>readme</a></p><h2 class="relative group">增强部分<div id=%E5%A2%9E%E5%BC%BA%E9%83%A8%E5%88%86 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%A2%9E%E5%BC%BA%E9%83%A8%E5%88%86 aria-label=锚点>#</a></span></h2><p>我们增强了 N2S 模型的损失函数部分<br>原始损失函数如下：</p><p>$$ E_ {x,y} |f(x)- y|^ {2} + E_ {x,y} |x- y|^ {2} = E_ {x} |f(x)- x|^ {2} + 2E_ {x} , y&lt;f(x)-y,x-y $$</p><p>其中，y代表不含噪声的图片（未知），x表示含噪声的图片，f(x) 表示经过模型处理的图片。</p><p>基于等式：x和y的差距等于 x 和 f(x )的差距与 f(x) 和 y 的差距的和：</p><p>$$ x-y=(x-f(x))+(f(x)-y) $$</p><p>变形可得：</p><p>$$ (x-y)-(f(x)-y) = x-f(x) $$</p><p>平方：</p><p>$$ E_ {x,y} || f(x)-y || - E_ {x,y} || (x-y) ^ {2} || = E_ {x} || f(x)-x || $$</p><p>结合平方差展开后移项，作者得到了以上等式。在经过复杂的数学方式证明后，作者得到了如下不等式，其中m表示图片中的像素多少，σ表示噪声的标准差：</p><p>$$ E_{x,y} ||f(x)- y|^ {2} + E_ {x}y||x- y|^ {2} \leqslant E_ {x}|f(x)- x||^ {2} + 2m \sigma E_{J} [ \frac{E||f(x)_ {1} -f(xJ_{c})J||^ {2} }{|J|}] ^ { \frac{1}{2}} $$</p><p>通过等式，作者将未知的y全部放在了左边。从图像处理角度分析，不等式左边表示不含噪声的图片和原图的差距（恒定）和模型输出图片与不含噪声图片差距的平方和。右面第一项表示模型输出与输入的平方和，右边第二项则是J不变项。从数学角度分析，我们期望模型输出图片f(x)与不含噪声图片y的差距越小越好，因此我们希望不等式右边也要越小越好。其中σ由于要同时得到x和y才能得知，N2S方法计算中实际使用了1来代替它。为了减小计算量以及更简洁的表达公式，我们把等式右边同除m，并使用λ来代替2σ，把结果作为训练过程中的损失函数，得到以下:</p><center>{% mathjax %}
\mathcal {L}(f) = \frac{E_{x} || f(x)-x || ^ {2}}{m} + \lambda _{inv}E_{J} [E_{x} \frac {||f(x)_{J}-f(xJ_{c})_{J}|| ^{2}}{|J|}]^{1/2}
{% endmathjax %}</center></br><p>Noise2Same方法通过创新性的不等式，得到了很好的结果。但是，其中也存在着一些缺陷，比如标准差σ无法直接取得，需要进行估计。在一些标准差较为恒定但与1差距较大的数据集中（比如同一老相机拍摄的图片集中可能含有相似的σ），由于σ会影响损失函数，所以收敛效果可能并没有那么好。这时，我们可以将σ一起列入未知项中，卷积神经网络每次迭代时将σ一起进行更新，这样可以有效提高模型的迭代速度。经过我们小组的研究，发现 $ E_{x}|| f(x) - x||^{2} $ 项约为 $ \sigma ^{2} $ 。由此，我们对n2s的损失函数进行了优化，使用$2 \sqrt {Ex||x-f(x)||^ {2}} $ 来代替λ。由此，现在的损失函数变为：</p><center>{% mathjax %}
\mathcal {L}(f) = E_ {x} || f(x)- x||^ {2} /m + 2\sqrt {Ex||x-f(x)||^ {2}} [ E_{x} ||f(x)_{J} - f(xJ_{c})_{J}||^ {2} / {|J|}]^{1/2}
{% endmathjax %}</center></br><p>经过对损失函数的改进，算法的收敛速度和整体性能得到了一定程度的提升.</p><h1 class="relative group"><a href=#readme>README</a><div id=readmereadme class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#readmereadme aria-label=锚点>#</a></span></h1><h2 class="relative group">项目介绍<div id=%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E9%A1%B9%E7%9B%AE%E4%BB%8B%E7%BB%8D aria-label=锚点>#</a></span></h2><p>本项目是基于自监督去噪模型<a href=https://github.com/divelab/Noise2Same target=_blank>Noise2Same</a>的改进，通过优化损失函数，提升了模型收敛速度和去噪效果.</p><h2 class="relative group">使用效果<div id=%E4%BD%BF%E7%94%A8%E6%95%88%E6%9E%9C class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E4%BD%BF%E7%94%A8%E6%95%88%E6%9E%9C aria-label=锚点>#</a></span></h2><p>去噪效果<br><figure><img class="my-0 rounded-md" loading=lazy src=https://i1.wp.com/img.erpweb.eu.org/imgs/2024/01/e1c64d796c0ed139.jpg alt></figure></p><h2 class="relative group">模型特点<div id=%E6%A8%A1%E5%9E%8B%E7%89%B9%E7%82%B9 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E6%A8%A1%E5%9E%8B%E7%89%B9%E7%82%B9 aria-label=锚点>#</a></span></h2><h3 class="relative group">介绍<div id=%E4%BB%8B%E7%BB%8D class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E4%BB%8B%E7%BB%8D aria-label=锚点>#</a></span></h3><p>本模型依赖于Noise2Same(下称N2S)模型的训练方法，在训练一定次数的N2S上继续训练得到Noise2SamePro(下称N2SP)，使得其收敛速度更快，图片去噪效果更好。<br>与N2S模型的对比<br><figure><img class="my-0 rounded-md" loading=lazy src=https://i1.wp.com/img.erpweb.eu.org/imgs/2024/01/631005200f54fca0.png alt></figure></p><table><thead><tr><th style=text-align:center></th><th style=text-align:center>方法</th><th style=text-align:center>PSNR</th></tr></thead><tbody><tr><td style=text-align:center>传统方法</td><td style=text-align:center>Input</td><td style=text-align:center>20.19</td></tr><tr><td style=text-align:center></td><td style=text-align:center>NLM</td><td style=text-align:center>22.73</td></tr><tr><td style=text-align:center>有监督</td><td style=text-align:center>Noise2True</td><td style=text-align:center>29.06</td></tr><tr><td style=text-align:center></td><td style=text-align:center>Noise2Noise</td><td style=text-align:center>28.86</td></tr><tr><td style=text-align:center>自监督</td><td style=text-align:center>Noise2Same</td><td style=text-align:center>27.09</td></tr><tr><td style=text-align:center></td><td style=text-align:center>Noise2SamePro</td><td style=text-align:center>27.10</td></tr></tbody></table><h3 class="relative group">数据集<div id=%E6%95%B0%E6%8D%AE%E9%9B%86 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E6%95%B0%E6%8D%AE%E9%9B%86 aria-label=锚点>#</a></span></h3><p>我们使用了N2S模型提供的<a href="https://drive.google.com/drive/folders/1VYMo1OoaGxoOLNx6-qIt2Wg03lsZw_kA?usp=sharing" target=_blank>数据集</a>,有关数据集构建和数据源的更多详细信息可以在 <a href=https://github.com/divelab/Noise2Same/blob/main/Denoising_data target=_blank>Denoising_data</a> 下找到.</p><h3 class="relative group">检查点<div id=%E6%A3%80%E6%9F%A5%E7%82%B9 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E6%A3%80%E6%9F%A5%E7%82%B9 aria-label=锚点>#</a></span></h3><p>我们提供基于上述数据集训练9万轮次的检查点，请点击<a href="https://drive.google.com/drive/folders/1SL7Bx1TZgj8Ns4BJppA_PalCSY-J4L1R?usp=drive_link" target=_blank>这里</a>下载.</p><h2 class="relative group">使用方法<div id=%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95 aria-label=锚点>#</a></span></h2><h3 class="relative group">环境<div id=%E7%8E%AF%E5%A2%83 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E7%8E%AF%E5%A2%83 aria-label=锚点>#</a></span></h3><pre tabindex=0><code>python==3.7.2
</code></pre><ul><li>tensorflow==1.15</li><li>scipy</li><li>scikit-image</li><li>tifffile</li><li>gdown</li><li>opencv-python</li><li>numpy</li><li>matplotlib</li><li>PIL</li></ul><h3 class="relative group">目录树<div id=%E7%9B%AE%E5%BD%95%E6%A0%91 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E7%9B%AE%E5%BD%95%E6%A0%91 aria-label=锚点>#</a></span></h3><pre tabindex=0><code>Noise2SamePro
├─ test.py *
├─ test_pro.py *
├─ network_configure.py
├─ models.py *
├─ requirements.txt
├─ basic_ops.py
├─ train.py *
├─ train_pro.py *
├─ utils
│  ├─ train_utils.py
│  ├─ evaluation_utils.py
│  └─ predict_utils.py
├─ README.md
├─ network.py
├─ resnet_module.py
├─ Denoising_data ------------------- 默认的数据集文件夹
├─ trained_model -------------------- 默认的模型存放位置
└─ test_single.py
</code></pre><p>您需要关注的是标记有<code>*</code>的文件/文件夹，后文会介绍通过修改这些文件进行自定义训练的方法.本项目源代码中同时含有N2S模型与N2SP模型，其中<code>test.py</code>,<code>train.py</code>是有关N2S模型的训练与测试部分；<code>test_pro.py</code>,<code>train_pro.py</code>是有关N2SP的训练与测试部分.</p><p>下文介绍N2SP的测试与训练方法，N2S与之类似(您也可参照N2S原仓库).</p><h3 class="relative group">使用<div id=%E4%BD%BF%E7%94%A8 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E4%BD%BF%E7%94%A8 aria-label=锚点>#</a></span></h3><p>在<code>test_single.py</code>中，请修改如下部分进行单张图片的去噪</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>picture</span> <span class=o>=</span> <span class=s1>&#39;man/&#39;</span> <span class=c1># Adjust path of the picture you want to test</span>
</span></span><span class=line><span class=cl><span class=n>model_dir</span> <span class=o>=</span> <span class=s1>&#39;N2S_PRO&#39;</span> <span class=c1># Adjust your model path</span>
</span></span><span class=line><span class=cl><span class=n>test_single</span><span class=p>(</span><span class=s1>&#39;test_single/&#39;</span> <span class=o>+</span> <span class=n>picture</span> <span class=o>+</span> <span class=s1>&#39;original_image.png&#39;</span><span class=p>,</span> <span class=n>model_dir</span><span class=p>,</span> <span class=s1>&#39;test_single/&#39;</span> <span class=o>+</span> <span class=n>picture</span> <span class=o>+</span> <span class=s1>&#39;denoised_image.png&#39;</span><span class=p>)</span>
</span></span></code></pre></div><p>执行以下命令并等待即可</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>python test_single.py
</span></span></code></pre></div><h3 class="relative group">测试<div id=%E6%B5%8B%E8%AF%95 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E6%B5%8B%E8%AF%95 aria-label=锚点>#</a></span></h3><p>如果您使用我们提供的检查点和默认路径，请将其放在<code>trained_model/</code>文件夹下(没有则请新建)<br>确保<code>test_pro.py</code>文件中检查点路径与数据集路径正确.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model_dir</span> <span class=o>=</span> <span class=s1>&#39;N2S_PRO-90000&#39;</span> <span class=c1># Adjust your model path</span>
</span></span><span class=line><span class=cl><span class=n>data_dir</span> <span class=o>=</span> <span class=s1>&#39;Denoising_data/test/&#39;</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Noise2Same</span><span class=p>(</span><span class=s1>&#39;trained_models/&#39;</span><span class=p>,</span> <span class=n>model_dir</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>in_channels</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span></code></pre></div><p>执行以下命令并等待即可</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>python test_pro.py
</span></span></code></pre></div><h3 class="relative group">训练<div id=%E8%AE%AD%E7%BB%83 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E8%AE%AD%E7%BB%83 aria-label=锚点>#</a></span></h3><p>N2SP的训练方法是：</p><blockquote><p>对于T次训练，采取<code>(T-a)</code>次对于N2S的训练和<code>a</code>次对N2SP的训练</p></blockquote><p>确保路径正确后，修改<code>train_pro.py</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model_dir</span> <span class=o>=</span> <span class=s1>&#39;N2S_PRO-8000&#39;</span> <span class=c1># Set model checkpoints save path</span>
</span></span><span class=line><span class=cl><span class=n>steps</span> <span class=o>=</span> <span class=mi>8000</span> <span class=c1># Set training steps</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>sgm_loss</span> <span class=o>=</span> <span class=mi>1</span> <span class=c1># the default sigma is 1</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Noise2Same</span><span class=p>(</span><span class=s1>&#39;trained_models/&#39;</span><span class=p>,</span> <span class=n>model_dir</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>in_channels</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>lmbd</span><span class=o>=</span><span class=mi>2</span><span class=o>*</span><span class=n>sgm_loss</span><span class=p>)</span> 
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span> <span class=n>patch_size</span><span class=o>=</span><span class=p>[</span><span class=mi>64</span><span class=p>,</span> <span class=mi>64</span><span class=p>],</span> <span class=n>validation</span><span class=o>=</span><span class=n>X_val</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=n>steps</span><span class=o>-</span><span class=mi>500</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Noise2SamePro</span><span class=p>(</span><span class=s1>&#39;trained_models/&#39;</span><span class=p>,</span> <span class=n>model_dir</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>in_channels</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>X</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span> <span class=n>patch_size</span><span class=o>=</span><span class=p>[</span><span class=mi>64</span><span class=p>,</span> <span class=mi>64</span><span class=p>],</span> <span class=n>validation</span><span class=o>=</span><span class=n>X_val</span><span class=p>[</span><span class=o>...</span><span class=p>,</span> <span class=kc>None</span><span class=p>],</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>steps</span><span class=o>=</span><span class=n>steps</span><span class=p>)</span>
</span></span></code></pre></div><p>在上面的数值中，<code>steps = 8000</code>是总步数，<code>sgm_loss = 1</code>是N2S模型使用的参数(默认为1),<code>steps=steps-500</code>中的500是N2SP的训练次数<br>即8000为 上述<code>T</code>;500为上述<code>a</code>.训练过程是进行7500次N2S的预训练，然后进行500次的附加训练.</p><p>调整完毕后，执行以下命令并等待即可</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>python train_pro.py
</span></span></code></pre></div><h3 class="relative group">其他事项<div id=%E5%85%B6%E4%BB%96%E4%BA%8B%E9%A1%B9 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E5%85%B6%E4%BB%96%E4%BA%8B%E9%A1%B9 aria-label=锚点>#</a></span></h3><h2 class="relative group">贡献者<div id=%E8%B4%A1%E7%8C%AE%E8%80%85 class=anchor></div><span class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style=text-decoration-line:none!important href=#%E8%B4%A1%E7%8C%AE%E8%80%85 aria-label=锚点>#</a></span></h2><p>本项目是天津大学2021图像处理结课作业的去噪部分，由郭骐瑞，刘原驰，罗嘉杰，周欣宇，陈嘉强，李进共同完成</p></div></div><script>var oid="views_posts/改进去噪模型-Noise2Same.md",oid_likes="likes_posts/改进去噪模型-Noise2Same.md"</script><script type=text/javascript src=/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q+oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script></section><footer class="pt-8 max-w-prose print:hidden"><div class=pt-8><hr class="border-dotted border-neutral-300 dark:border-neutral-600"><div class="flex justify-between pt-3"><span></span><span><a class="flex text-right group ml-3" href=/posts/%E5%AE%9A%E5%88%B6%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%91%BD%E4%BB%A4%E6%A0%91%E5%AE%9E%E7%8E%B0/><span class="flex flex-col"><span class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500">定制系统的命令树实现</span>
<span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400"><time datetime=2024-12-17T20:11:02+00:00>2024 December 17</time>
</span></span><span class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400">&rarr;</span>
<span class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400">&larr;</span></a></span></div></div></footer></article><div id=top-scroller class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0"><a href=#the-top class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400" aria-label=返回顶部 title=返回顶部>&uarr;</a></div></main><footer id=site-footer class="py-10 print:hidden"><div class="flex items-center justify-between"><p class="text-sm text-neutral-500 dark:text-neutral-400">&copy;
2025
Lessthread</p><p class="text-xs text-neutral-500 dark:text-neutral-400">由 <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://gohugo.io/ target=_blank rel="noopener noreferrer">Hugo</a> & <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href=https://blowfish.page/ target=_blank rel="noopener noreferrer">Blowfish</a> 强力驱动</p></div><script>mediumZoom(document.querySelectorAll("img:not(.nozoom)"),{margin:24,background:"rgba(0,0,0,0.5)",scrollOffset:0})</script><script type=text/javascript src=/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh+sCQ0E53ghYrxgYqw+0GCRyIEpA=="></script></footer><div id=search-wrapper class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]" data-url=https://blog.lessthread.top/ style=z-index:500><div id=search-modal class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"><header class="relative z-10 flex items-center justify-between flex-none px-2"><form class="flex items-center flex-auto min-w-0"><div class="flex items-center justify-center w-8 h-8 text-neutral-400"><span class="relative block icon"><svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" viewBox="0 0 512 512"><path fill="currentcolor" d="M505 442.7 405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9.0 208 0S0 93.1.0 208s93.1 208 208 208c48.3.0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9.0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7.0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7.0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg></span></div><input type=search id=search-query class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent" placeholder=搜索 tabindex=0></form><button id=close-search-button class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400" title="关闭 (Esc)">
<span class="relative block icon"><svg viewBox="0 0 320 512"><path fill="currentcolor" d="M310.6 361.4c12.5 12.5 12.5 32.75.0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3 54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75.0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75.0-45.25s32.75-12.5 45.25.0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25.0s12.5 32.75.0 45.25l-105.4 105.4L310.6 361.4z"/></svg></span></button></header><section class="flex-auto px-2 overflow-auto"><ul id=search-results></ul></section></div></div></div></body></html>