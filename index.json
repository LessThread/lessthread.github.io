[{"content":"","date":"2025 January 27","externalUrl":null,"permalink":"/","section":"","summary":"","title":"","type":"page"},{"content":"","date":"2025 January 27","externalUrl":null,"permalink":"/posts/","section":"","summary":"","title":"","type":"posts"},{"content":"\rCUDA 简介 #\r引用自wiki:\nCUDA（Compute Unified Device Architecture，统一计算架构）是由英伟达NVIDIA所推出的一种软硬件集成技术，是该公司对于GPGPU的正式名称。透过这个技术，用户可利用NVIDIA的GPU进行图像处理之外的运算.\n简单来说,就是让显卡能够运行除了图形相关运算外,也可以作为计算卡加速其他的可编程计算,包括 AI 相关的推理.\n由于 GPU 计算单元远超 CPU ,所以大多数 AI 模型需要使用 GPU 支持以达到可接受的 训练/推理 时间.现行的主流深度学习框架 (torch,tensorflow) 对CUDA的适配最为良好和易用,因此推荐初学者和 AI 一般用户使用 Nvidia 显卡.\n从 CUDA 到 python #\r底 层 | GPU 硬件 实际负责运算的`基本硬件` | | 驱动程序 操作系统层,直接指挥硬件的工作,图形渲染和科学计算都需要的`基本软件` | | CUDA 工具包 提供基本可编程性,高级用户可以通过 CUDA 编程实现GPU计算 | | Conda 环境 隔离python环境,使得 同一操作系统/环境 下切换不同python的需求更方便 | | python 深度学习框架的依赖语言 | ↓ 深度学习框架 提供高可编程的 AI 框架 顶 层 接下来让我们举例说明其中的兼容性\nGPU 硬件 #\r依据显卡架构提供支持CUDA版本的上限 (下面表格摘自wiki百科,更详细的情况请查阅英文wiki,中文更新略有延迟)\nCUDA 版本 支持的计算能力 微架构 备注 1.0[10] 1.0 – 1.1 Tesla - 1.1 1.0 – 1.1+x Tesla - 2.0 1.0 – 1.1+x Tesla - 2.1 – 2.3.1[11][12][13][14] 1.0 – 1.3 Tesla - 3.0 – 3.1[15][16] 1.0 – 2.0 Tesla, Fermi - 3.2[17] 1.0 – 2.1 Tesla, Fermi - 4.0 – 4.2 1.0 – 2.1+x Tesla, Fermi - 5.0 – 5.5 1.0 – 3.5 Tesla, Fermi, Kepler - 6.0 1.0 – 3.5 Tesla, Fermi, Kepler - 6.5 1.1 – 5.x Tesla, Fermi, Kepler, Maxwell 最后支持计算能力 1.x (Tesla) 的版本 7.0 – 7.5 2.0 – 5.x Fermi, Kepler, Maxwell - 8.0 2.0 – 6.x Fermi, Kepler, Maxwell, Pascal 最后支持计算能力 2.x (Fermi) 的版本；GTX 1070Ti 不受支持 9.0 – 9.2 3.0 – 7.2 Kepler, Maxwell, Pascal, Volta Pascal GTX 1070Ti 不受 CUDA SDK 9.0 支持，但受 CUDA SDK 9.2支持 10.0 – 10.2 3.0 – 7.5 Kepler, Maxwell, Pascal, Volta, Turing 最后支持计算能力 3.x (Kepler) 的版本；CUDA SDK 10.2 是最后能用于 macOS 的官方版本，在未来的版本中 macOS 将不被支持 11.0 – 3.5 - 8.6 Maxwell, Pascal, Volta, Turing, Ampere - 在选择硬件时,请结合您项目的实际需求,请特别注意, CUDA 虽然有较好的兼容性设计,但是仍然存在较新显卡不能支持低版本 CUDA 的情况(详细情况请查询 wiki 的 CUDA 各版本算力支持范围)\nGPU 驱动 #\r依据显卡nvida官网上选择,如果您没有特殊需求,建议使用最新版本驱动 安装完成后,使用nvidia-smi 即可查看 GPU 状况.\n+-----------------------------------------------------------------------------+ | NVIDIA-SMI 526.98 Driver Version: 526.98 CUDA Version: 12.0 | |-------------------------------+----------------------+----------------------+ | GPU Name TCC/WDDM | Bus-Id Disp.A | Volatile Uncorr. ECC | | Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. | | | | MIG M. | |===============================+======================+======================| | 0 NVIDIA P106-100 TCC | 00000000:10:00.0 Off | N/A | | 33% 50C P0 29W / 120W | 8MiB / 6144MiB | 0% Default | | | | N/A | +-------------------------------+----------------------+----------------------+ +-----------------------------------------------------------------------------+ | Processes: | | GPU GI CI PID Type Process name GPU Memory | | ID ID Usage | |=============================================================================| | No running processes found | +-----------------------------------------------------------------------------+ NVIDIA-SMI 为 Nvidia-smi 版本 Driver Version 为驱动版本 CUDA Version 为该驱动支持的 CUDA 最高版本 CUDA 版本 #\r请依据项目提供的条件和自身驱动选择合适的 CUDA 版本,如果项目未指明,请根据 python/torch/tf 框架版本结合项目时间推测,通常可使用 CUDA 11.x 版本\n您可以通过下面的方法安装cuda\n直接安装,通过 nvidia 官网安装相应版本的 CUDA 工具包\n通过conda安装 ( 如果您正在服务器上,请考虑使用非 root 安装 miniconda 方法 ), 这里以 pytorch 为例\nconda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia 您可以参考所需的学习框架版本,安装合适的 CUDA. 也可以在相关学习框架的官网上查找适配的 CUDA 版本\nconda安装 #\r推荐使用 miniconda\npython 和相关包安装 #\r略\n","date":"2025 January 27","externalUrl":null,"permalink":"/posts/cuda%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%8E%AF%E5%A2%83%E7%AE%80%E4%BB%8B/","section":"","summary":"","title":"CUDA与深度学习环境简介","type":"posts"},{"content":"\r前言 #\r基于N2S模型进行了修改\n源码地址\nreadme\n增强部分 #\r我们增强了 N2S 模型的损失函数部分\n原始损失函数如下：\n$$ E_ {x,y} |f(x)- y|^ {2} + E_ {x,y} |x- y|^ {2} = E_ {x} |f(x)- x|^ {2} + 2E_ {x} , y\u0026lt;f(x)-y,x-y $$\n其中，y代表不含噪声的图片（未知），x表示含噪声的图片，f(x) 表示经过模型处理的图片。\n基于等式：x和y的差距等于 x 和 f(x )的差距与 f(x) 和 y 的差距的和：\n$$ x-y=(x-f(x))+(f(x)-y) $$\n变形可得：\n$$ (x-y)-(f(x)-y) = x-f(x) $$\n平方：\n$$ E_ {x,y} || f(x)-y || - E_ {x,y} || (x-y) ^ {2} || = E_ {x} || f(x)-x || $$\n结合平方差展开后移项，作者得到了以上等式。在经过复杂的数学方式证明后，作者得到了如下不等式，其中m表示图片中的像素多少，σ表示噪声的标准差：\n$$ E_{x,y} ||f(x)- y|^ {2} + E_ {x}y||x- y|^ {2} \\leqslant E_ {x}|f(x)- x||^ {2} + 2m \\sigma E_{J} [ \\frac{E||f(x)_ {1} -f(xJ_{c})J||^ {2} }{|J|}] ^ { \\frac{1}{2}} $$\n通过等式，作者将未知的y全部放在了左边。从图像处理角度分析，不等式左边表示不含噪声的图片和原图的差距（恒定）和模型输出图片与不含噪声图片差距的平方和。右面第一项表示模型输出与输入的平方和，右边第二项则是J不变项。从数学角度分析，我们期望模型输出图片f(x)与不含噪声图片y的差距越小越好，因此我们希望不等式右边也要越小越好。其中σ由于要同时得到x和y才能得知，N2S方法计算中实际使用了1来代替它。为了减小计算量以及更简洁的表达公式，我们把等式右边同除m，并使用λ来代替2σ，把结果作为训练过程中的损失函数，得到以下:\n{% mathjax %}\r\\mathcal {L}(f) = \\frac{E_{x} || f(x)-x || ^ {2}}{m} + \\lambda _{inv}E_{J} [E_{x} \\frac {||f(x)_{J}-f(xJ_{c})_{J}|| ^{2}}{|J|}]^{1/2}\r{% endmathjax %}\rNoise2Same方法通过创新性的不等式，得到了很好的结果。但是，其中也存在着一些缺陷，比如标准差σ无法直接取得，需要进行估计。在一些标准差较为恒定但与1差距较大的数据集中（比如同一老相机拍摄的图片集中可能含有相似的σ），由于σ会影响损失函数，所以收敛效果可能并没有那么好。这时，我们可以将σ一起列入未知项中，卷积神经网络每次迭代时将σ一起进行更新，这样可以有效提高模型的迭代速度。经过我们小组的研究，发现 $ E_{x}|| f(x) - x||^{2} $ 项约为 $ \\sigma ^{2} $ 。由此，我们对n2s的损失函数进行了优化，使用$2 \\sqrt {Ex||x-f(x)||^ {2}} $ 来代替λ。由此，现在的损失函数变为：\n{% mathjax %}\r\\mathcal {L}(f) = E_ {x} || f(x)- x||^ {2} /m + 2\\sqrt {Ex||x-f(x)||^ {2}} [ E_{x} ||f(x)_{J} - f(xJ_{c})_{J}||^ {2} / {|J|}]^{1/2}\r{% endmathjax %}\r经过对损失函数的改进，算法的收敛速度和整体性能得到了一定程度的提升.\nREADME #\r项目介绍 #\r本项目是基于自监督去噪模型Noise2Same的改进，通过优化损失函数，提升了模型收敛速度和去噪效果.\n使用效果 #\r去噪效果\n模型特点 #\r介绍 #\r本模型依赖于Noise2Same(下称N2S)模型的训练方法，在训练一定次数的N2S上继续训练得到Noise2SamePro(下称N2SP)，使得其收敛速度更快，图片去噪效果更好。\n与N2S模型的对比\n方法 PSNR 传统方法 Input 20.19 NLM 22.73 有监督 Noise2True 29.06 Noise2Noise 28.86 自监督 Noise2Same 27.09 Noise2SamePro 27.10 数据集 #\r我们使用了N2S模型提供的数据集,有关数据集构建和数据源的更多详细信息可以在 Denoising_data 下找到.\n检查点 #\r我们提供基于上述数据集训练9万轮次的检查点，请点击这里下载.\n使用方法 #\r环境 #\rpython==3.7.2 tensorflow==1.15 scipy scikit-image tifffile gdown opencv-python numpy matplotlib PIL 目录树 #\rNoise2SamePro\r├─ test.py *\r├─ test_pro.py *\r├─ network_configure.py\r├─ models.py *\r├─ requirements.txt\r├─ basic_ops.py\r├─ train.py *\r├─ train_pro.py *\r├─ utils\r│ ├─ train_utils.py\r│ ├─ evaluation_utils.py\r│ └─ predict_utils.py\r├─ README.md\r├─ network.py\r├─ resnet_module.py\r├─ Denoising_data ------------------- 默认的数据集文件夹\r├─ trained_model -------------------- 默认的模型存放位置\r└─ test_single.py 您需要关注的是标记有*的文件/文件夹，后文会介绍通过修改这些文件进行自定义训练的方法.本项目源代码中同时含有N2S模型与N2SP模型，其中test.py,train.py是有关N2S模型的训练与测试部分；test_pro.py,train_pro.py是有关N2SP的训练与测试部分.\n下文介绍N2SP的测试与训练方法，N2S与之类似(您也可参照N2S原仓库).\n使用 #\r在test_single.py中，请修改如下部分进行单张图片的去噪\npicture = \u0026#39;man/\u0026#39; # Adjust path of the picture you want to test model_dir = \u0026#39;N2S_PRO\u0026#39; # Adjust your model path test_single(\u0026#39;test_single/\u0026#39; + picture + \u0026#39;original_image.png\u0026#39;, model_dir, \u0026#39;test_single/\u0026#39; + picture + \u0026#39;denoised_image.png\u0026#39;) 执行以下命令并等待即可\npython test_single.py 测试 #\r如果您使用我们提供的检查点和默认路径，请将其放在trained_model/文件夹下(没有则请新建)\n确保test_pro.py文件中检查点路径与数据集路径正确.\nmodel_dir = \u0026#39;N2S_PRO-90000\u0026#39; # Adjust your model path data_dir = \u0026#39;Denoising_data/test/\u0026#39; model = Noise2Same(\u0026#39;trained_models/\u0026#39;, model_dir, dim=2, in_channels=1) 执行以下命令并等待即可\npython test_pro.py 训练 #\rN2SP的训练方法是：\n对于T次训练，采取(T-a)次对于N2S的训练和a次对N2SP的训练\n确保路径正确后，修改train_pro.py\nmodel_dir = \u0026#39;N2S_PRO-8000\u0026#39; # Set model checkpoints save path steps = 8000 # Set training steps sgm_loss = 1 # the default sigma is 1 model = Noise2Same(\u0026#39;trained_models/\u0026#39;, model_dir, dim=2, in_channels=1, lmbd=2*sgm_loss) model.train(X[..., None], patch_size=[64, 64], validation=X_val[..., None], batch_size=64, steps=steps-500) model = Noise2SamePro(\u0026#39;trained_models/\u0026#39;, model_dir, dim=2, in_channels=1) model.train(X[..., None], patch_size=[64, 64], validation=X_val[..., None], batch_size=64, steps=steps) 在上面的数值中，steps = 8000是总步数，sgm_loss = 1是N2S模型使用的参数(默认为1),steps=steps-500中的500是N2SP的训练次数\n即8000为 上述T;500为上述a.训练过程是进行7500次N2S的预训练，然后进行500次的附加训练.\n调整完毕后，执行以下命令并等待即可\npython train_pro.py 其他事项 #\r贡献者 #\r本项目是天津大学2021图像处理结课作业的去噪部分，由郭骐瑞，刘原驰，罗嘉杰，周欣宇，陈嘉强，李进共同完成\n","date":"2024 January 17","externalUrl":null,"permalink":"/posts/%E6%94%B9%E8%BF%9B%E5%8E%BB%E5%99%AA%E6%A8%A1%E5%9E%8B-noise2same/","section":"","summary":"","title":"改进去噪模型-Noise2Same","type":"posts"},{"content":"","externalUrl":null,"permalink":"/about/","section":"","summary":"","title":"","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"},{"content":"","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"}]